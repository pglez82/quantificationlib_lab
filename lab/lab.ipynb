{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller de cuantificaci칩n: Estimaci칩n de prevalencias por clase\n",
    "Pontentes: Pablo Gonzalez (gonzalezgpablo@uniovi.es) y Olaya P칠rez (perezolaya@uniovi.es)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pglez82/quantificationlib_lab/blob/master/lab/lab_solucion.ipynb)\n",
    "\n",
    "### Parte 1: Descarga del dataset necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://zenodo.org/records/11661820/files/T1.train_dev.zip?download=1\"\n",
    "zip_path = \"T1.train_dev.zip\"\n",
    "extracted_folder = \"T1.train_dev\"\n",
    "\n",
    "# Download with system wget (Jupyter syntax)\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget -O $zip_path \"$zip_url\"\n",
    "else:\n",
    "    print(\"ZIP file already exists.\")\n",
    "\n",
    "# Extract if not already extracted\n",
    "if not os.path.exists(extracted_folder):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Instalaci칩n de las librer칤as necesarias\n",
    "Necesitaremos:\n",
    "- **pandas**: para cargar los datos y manejarlos de manera sencilla.\n",
    "- **matplotlib**: para realizar gr치ficos.\n",
    "- **scikit-learn**: para utilizar clasificadores como por ejemplo Logistic Regression.\n",
    "- **quantificationlib**: librer칤a con los m칠todos de cuantificaci칩n implementados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install quantificationlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3. Leyendo el dataset.\n",
    "Este dataset contiene reviews de productos de amazon. Cada review puede ser positiva o negativa (campo `label`). El texto de cada review ha sido convertido a una representaci칩n num칠rica para su facilidad de uso. Diponemos de 5000 ejemplos de entrenamiento (5000 opiniones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('T1.train_dev/T1/public/training_data.txt')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la prevalencia de las clases original en el dataset de entrenamiento.\n",
    "Como podemos ver, un alto porcentaje de las opiniones son positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count examples per label\n",
    "label_counts = dataset['label'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(label_counts.index.astype(str), label_counts.values)\n",
    "plt.xlabel('Etiqueta (0 negativa, 1 positiva)')\n",
    "plt.ylabel('N칰mero de ejemplos')\n",
    "plt.title('Distribuci칩n')\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a cuantificar. El m칠todo Clasificar y Contar\n",
    "Vamos a empezar con la soluci칩n trivial del problema de la cuantificaci칩n: entrenar un clasificador y contar las predicciones de cada ejemplo de la bag de test que queremos cuantificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "X = dataset.drop(columns=[\"label\"]).values\n",
    "y = dataset[\"label\"].values\n",
    "\n",
    "#Dividimos nuestro dataset en train y test, separando el 30% de los ejemplos para test y asegurando que la proporci칩n original de etiquetas se mantiene en ambos conjuntos.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(y_train)} ejemplos (Proporci칩n positivos: {np.mean(y_train):.2f}) | Test: {len(y_test)} ejemplos (Proporci칩n positivos: {np.mean(y_test):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un clasificador y clasificamos lo ejemplos de test. Como podemos ver, el error absoluto de este cuantificador (AE) es bajo, predice bastante bien la prevalencia de la clse positiva en la bag de test. Este problema es en realidad trivial ya que en nuestro setup la prevalencia de las clases **no ha cambiado** entre train y test: $P_{train}(y)=P_{test}(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# Predeccimos los ejemplos de test y contamos la proporci칩n de positivos en las predicciones.\n",
    "\n",
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje positivos): {cc_prevalence:.4f}\")\n",
    "print(f\"Porcentaje positivos real: {true_prevalence:.4f}\")\n",
    "print(f\"Error absoluto cuantificador: {np.abs(cc_prevalence-true_prevalence):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 쯈u칠 sucede si la distribuci칩n $P(y)$ cambia entre train y test $P_{train}(y) \\neq P_{test}(y)$?\n",
    "Para probarlo, generamos una nueva bolsa de test con 500 ejemplos, pero en este caso, la mayor칤a van a ser negativos (400 de 500).\n",
    "Como podemos comprobar ahora, si repetimos el procedimiento de antes y utilizamos CC para cuantificar, podemos comprobar como el error absoluto entre la predicci칩n del cuantificador y la prevalencia real es mucho mayor.\n",
    "\n",
    "游닇***Hazlo tu mismo**: Escribe el c칩digo necesario para clasificar los ejemplos de test con el clasificador entrenado y contar cuantos ejemplos pertenecen a la clase positiva. Imprime tambi칠n el error absoluto de esta estimaci칩n de la prevalencia $AE=|\\hat{p}-p|$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los 칤ndices de los ejemplos negativos y positivos en el conjunto de test\n",
    "neg_indices = np.where(y_test == 0)[0]\n",
    "pos_indices = np.where(y_test == 1)[0]\n",
    "\n",
    "# Elegimos el n칰mero de ejemplos negativos y positivos que queremos en nuestra bag\n",
    "n_neg, n_pos = 400, 100\n",
    "\n",
    "# Muestreamos aleatoriamente con reemplazmiento los 칤ndices de los ejemplos negativos y positivos\n",
    "sampled_neg = np.random.choice(neg_indices, size=n_neg, replace=True)\n",
    "sampled_pos = np.random.choice(pos_indices, size=n_pos, replace=True)\n",
    "\n",
    "# Combinamos y barajamos los 칤ndices de la bag\n",
    "bag_indices = np.concatenate([sampled_neg, sampled_pos])\n",
    "np.random.shuffle(bag_indices)\n",
    "\n",
    "# Creamos la bag con los ejemplos seleccionados\n",
    "X_bag = X_test[bag_indices]\n",
    "y_bag = y_test[bag_indices]\n",
    "\n",
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizando la cuantificaci칩n (quantificationlib)\n",
    "\n",
    "Hasta ahora hemos cuantificado, con un cuantificador trivial (CC) a mano. Para cuantificar disponemos de software espec칤fico, como por ejemplo la librer칤a de cuantificaci칩n **quantificationlib** (https://aicgijon.github.io/quantificationlib/).\n",
    "\n",
    "Veamos como utilizar CC usando quantificationlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.cc import CC\n",
    "from quantificationlib.metrics.multiclass import mean_absolute_error\n",
    "\n",
    "# Creamos un objeto CC que corresponde al m칠todo clasificar y contar (CC) e indicamos que queremos el mismo clasificador que hemos utilizado antes (clf).\n",
    "quantifier_cc = CC(estimator_test=clf)\n",
    "quantifier_cc.fit(X_train,y_train)\n",
    "# Predeccimos la misma bag con el cuantificador CC (deber칤amos de obtener los mismos resultados que antes)\n",
    "p_pred=quantifier_cc.predict(X_bag)\n",
    "\n",
    "true_prevalence = np.array([0.8,0.2])\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje postivos): {p_pred[1]}\")\n",
    "print(f\"Prevalencia real: {true_prevalence[1]}\")\n",
    "# Tambi칠n disponemos de funciones para calcular errores de cuantificaci칩n como el error absoluto\n",
    "print(f\"Error absoluto cuantificador: {mean_absolute_error(p_pred,true_prevalence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando cuantificadores m치s avanzados\n",
    "En este caso vamos a utilizar un cuantificador especialmente dise침ador para lidiar con situaciones de prior probability shift. Este m칠todo es un cuantificador b치sico conocido como Adjusted Count (AC).\n",
    "\n",
    "Como podemos ver este cuantificador mejora much칤simo el resultado de CC.\n",
    "\n",
    "游닇 ***Hazlo tu mismo**: A침ade el c칩digo necesario para cuantificar usando **AC** implementado en quantificationlib e imprimir la prevalencia obtenida y el error cometido. Ten en cuenta que AC necesita un estimador de train (para estimar el tpr y el fpr, y un estimador de test. Estos dos clasificadores suelen ser el mismo.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.ac import AC\n",
    "\n",
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando correctamente un cuantificador\n",
    "\n",
    "Hasta ahora hemos hecho nuestras pruebas sobre una sola bag, con una prevalencia fija. Pero, no ser칤a m치s adecuado crear varias bags con prior probability shift y calcular el error que cometemos? Esto se puede realizar f치cilmente con un generador de bags incluido en **quantificationlib**. Veamos como se usa.\n",
    "\n",
    "游닇 ***Hazlo t칰 mismo**: Utilizando `prev_true` e `indexes` devuelto, eval칰a los cuantificadores CC y AC en cada una de las bags, calculando el error absoluto medio para las 50 bags. `prev_true` tendr치 una forma (n_classes, n_bags) e `indexes` tendr치 una forma (bag_size, n_bags).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "\n",
    "n_bags = 50\n",
    "bag_size = 500\n",
    "\n",
    "bag_generator = PriorShift_BagGenerator(n_bags=n_bags, bag_size=bag_size, min_prevalence=None)\n",
    "# prev_true es la prevalencia real de cada bag y indexes son los 칤ndices de los ejemplos de test que pertenecen a cada bag.\n",
    "# prev_true tiene forma (2, n_bags) y indexes tiene forma (bag_size, n_bags)\n",
    "prev_true, indexes = bag_generator.generate_bags(X_test, y_test)\n",
    "\n",
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizandolo gr치ficamente\n",
    "Otra manera de ver el rendimiento de los cuantificadores es visualizarlo gr치ficamente. Podemos pintar en un gr치fico de dos dimesiones, donde el eje X representa la prevalencia real y el eje Y representa la prevalencia estimada. La linea x=y representar칤a el cuantificador perfecto (aquel que es capaz de predecir la prevalencia real de la bag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_true = prev_true[1, :]  # Prevalencia real de la clase positiva\n",
    "preds_cc = preds_cc[1, :]  # Predicciones del cuantificador CC\n",
    "preds_ac = preds_ac[1, :]  # Predicciones del cuantificador AC\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Cuantificador perfecto (y = x)')  # l칤nea y=x\n",
    "plt.scatter(prev_true, preds_cc, color='green', label='CC', marker='o')\n",
    "plt.scatter(prev_true, preds_ac, color='red', label='AC', marker='s')\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.xlabel('Prevalencia real')\n",
    "plt.ylabel('Prevalencia estimada')\n",
    "plt.title('Comparaci칩n de predicciones de cuantificadores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Entrena dos cuantificadores m치s. El primero basado en distribution matching (DFy) y el segundo basado en el agoritmo EM (EM), compara los resultados con AC y CC. Pinta estos cuantificadores en una gr치fica como la vista anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "from quantificationlib.multiclass.em import EM\n",
    "from quantificationlib.multiclass.df import DFy\n",
    "\n",
    "n_bags = 50\n",
    "bag_size = 500\n",
    "\n",
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Utiliza los 5000 ejemplos de entrenamiento para reentrenar tus cuatro cuantificadores. Usa estos cuantificadores para cuantificar las 1000 muestras presentes en el directorio T1.train_dev/T1/public/dev_samples. Visualizalo tambi칠n gr치ficamente.\n",
    "La prevalencia real de cada bag est치 en el archivo dev_prevalences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 [Extra]. Hiperpar치metros de los cuantificadores.\n",
    "Algunos cuantificadores, como por ejemplo DFy tienen hiper-par치metros, como por ejemplo el n칰mero de bins o la funci칩n de distancia utilizada para comparar las distribuciones. Prueba a cambiar estos hiperpar치metros y volver a ejecutar, 쯘ncuentras alguna diferencia? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c칩digo aqu칤\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4 [Extra]. Usando un dataset multiclase.\n",
    "\n",
    "Prueba a entrenar los cuantificadores utilizando un dataset multiclase: https://zenodo.org/records/11661820/files/T2.train_dev.zip?download=1. Todos los cuantificadores que hemos utilizado anteriormente son capaces tambi칠n de resolver problemas multiclase.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
