{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller de cuantificación: Estimación de prevalencias por clase\n",
    "Pontentes: Pablo Gonzalez (gonzalezgpablo@uniovi.es) y Olaya Pérez (perezolaya@uniovi.es)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pglez82/quantificationlib_lab/blob/master/lab/lab_solucion.ipynb)\n",
    "\n",
    "### Parte 1: Descarga del dataset necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://zenodo.org/records/11661820/files/T1.train_dev.zip?download=1\"\n",
    "zip_path = \"T1.train_dev.zip\"\n",
    "extracted_folder = \"T1.train_dev\"\n",
    "\n",
    "# Download with system wget (Jupyter syntax)\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget -O $zip_path \"$zip_url\"\n",
    "else:\n",
    "    print(\"ZIP file already exists.\")\n",
    "\n",
    "# Extract if not already extracted\n",
    "if not os.path.exists(extracted_folder):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Instalación de las librerías necesarias\n",
    "Necesitaremos:\n",
    "- **pandas**: para cargar los datos y manejarlos de manera sencilla.\n",
    "- **matplotlib**: para realizar gráficos.\n",
    "- **scikit-learn**: para utilizar clasificadores como por ejemplo Logistic Regression.\n",
    "- **quantificationlib**: librería con los métodos de cuantificación implementados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install quantificationlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3. Leyendo el dataset.\n",
    "Este dataset contiene reviews de productos de amazon. Cada review puede ser positiva o negativa (campo `label`). El texto de cada review ha sido convertido a una representación numérica para su facilidad de uso. Diponemos de 5000 ejemplos de entrenamiento (5000 opiniones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('T1.train_dev/T1/public/training_data.txt')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la prevalencia de las clases original en el dataset de entrenamiento.\n",
    "Como podemos ver, un alto porcentaje de las opiniones son positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count examples per label\n",
    "label_counts = dataset['label'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(label_counts.index.astype(str), label_counts.values)\n",
    "plt.xlabel('Etiqueta (0 negativa, 1 positiva)')\n",
    "plt.ylabel('Número de ejemplos')\n",
    "plt.title('Distribución')\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a cuantificar. El método Clasificar y Contar\n",
    "Vamos a empezar con la solución trivial del problema de la cuantificación: entrenar un clasificador y contar las predicciones de cada ejemplo de la bag de test que queremos cuantificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "X = dataset.drop(columns=[\"label\"]).values\n",
    "y = dataset[\"label\"].values\n",
    "\n",
    "#Dividimos nuestro dataset en train y test, separando el 30% de los ejemplos para test y asegurando que la proporción original de etiquetas se mantiene en ambos conjuntos.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(y_train)} ejemplos (Proporción positivos: {np.mean(y_train):.2f}) | Test: {len(y_test)} ejemplos (Proporción positivos: {np.mean(y_test):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un clasificador y clasificamos lo ejemplos de test. Como podemos ver, el error absoluto de este cuantificador (AE) es bajo, predice bastante bien la prevalencia de la clse positiva en la bag de test. Este problema es en realidad trivial ya que en nuestro setup la prevalencia de las clases **no ha cambiado** entre train y test: $P_{train}(y)=P_{test}(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# Predeccimos los ejemplos de test y contamos la proporción de positivos en las predicciones.\n",
    "\n",
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje positivos): {cc_prevalence:.4f}\")\n",
    "print(f\"Porcentaje positivos real: {true_prevalence:.4f}\")\n",
    "print(f\"Error absoluto cuantificador: {np.abs(cc_prevalence-true_prevalence):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué sucede si la distribución $P(y)$ cambia entre train y test $P_{train}(y) \\neq P_{test}(y)$?\n",
    "Para probarlo, generamos una nueva bolsa de test con 500 ejemplos, pero en este caso, la mayoría van a ser negativos (400 de 500).\n",
    "Como podemos comprobar ahora, si repetimos el procedimiento de antes y utilizamos CC para cuantificar, podemos comprobar como el error absoluto entre la predicción del cuantificador y la prevalencia real es mucho mayor.\n",
    "\n",
    "📝***Hazlo tu mismo**: Escribe el código necesario para clasificar los ejemplos de test con el clasificador entrenado y contar cuantos ejemplos pertenecen a la clase positiva. Imprime también el error absoluto de esta estimación de la prevalencia $AE=|\\hat{p}-p|$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los índices de los ejemplos negativos y positivos en el conjunto de test\n",
    "neg_indices = np.where(y_test == 0)[0]\n",
    "pos_indices = np.where(y_test == 1)[0]\n",
    "\n",
    "# Elegimos el número de ejemplos negativos y positivos que queremos en nuestra bag\n",
    "n_neg, n_pos = 400, 100\n",
    "\n",
    "# Muestreamos aleatoriamente con reemplazmiento los índices de los ejemplos negativos y positivos\n",
    "sampled_neg = np.random.choice(neg_indices, size=n_neg, replace=True)\n",
    "sampled_pos = np.random.choice(pos_indices, size=n_pos, replace=True)\n",
    "\n",
    "# Combinamos y barajamos los índices de la bag\n",
    "bag_indices = np.concatenate([sampled_neg, sampled_pos])\n",
    "np.random.shuffle(bag_indices)\n",
    "\n",
    "# Creamos la bag con los ejemplos seleccionados\n",
    "X_bag = X_test[bag_indices]\n",
    "y_bag = y_test[bag_indices]\n",
    "\n",
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizando la cuantificación (quantificationlib)\n",
    "\n",
    "Hasta ahora hemos cuantificado, con un cuantificador trivial (CC) a mano. Para cuantificar disponemos de software específico, como por ejemplo la librería de cuantificación **quantificationlib** (https://aicgijon.github.io/quantificationlib/).\n",
    "\n",
    "Veamos como utilizar CC usando quantificationlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.cc import CC\n",
    "from quantificationlib.metrics.multiclass import mean_absolute_error\n",
    "\n",
    "# Creamos un objeto CC que corresponde al método clasificar y contar (CC) e indicamos que queremos el mismo clasificador que hemos utilizado antes (clf).\n",
    "quantifier_cc = CC(estimator_test=clf)\n",
    "quantifier_cc.fit(X_train,y_train)\n",
    "# Predeccimos la misma bag con el cuantificador CC (deberíamos de obtener los mismos resultados que antes)\n",
    "p_pred=quantifier_cc.predict(X_bag)\n",
    "\n",
    "true_prevalence = np.array([0.8,0.2])\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje postivos): {p_pred[1]}\")\n",
    "print(f\"Prevalencia real: {true_prevalence[1]}\")\n",
    "# También disponemos de funciones para calcular errores de cuantificación como el error absoluto\n",
    "print(f\"Error absoluto cuantificador: {mean_absolute_error(p_pred,true_prevalence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando cuantificadores más avanzados\n",
    "En este caso vamos a utilizar un cuantificador especialmente diseñador para lidiar con situaciones de prior probability shift. Este método es un cuantificador básico conocido como Adjusted Count (AC).\n",
    "\n",
    "Como podemos ver este cuantificador mejora muchísimo el resultado de CC.\n",
    "\n",
    "📝 ***Hazlo tu mismo**: Añade el código necesario para cuantificar usando **AC** implementado en quantificationlib e imprimir la prevalencia obtenida y el error cometido. Ten en cuenta que AC necesita un estimador de train (para estimar el tpr y el fpr, y un estimador de test. Estos dos clasificadores suelen ser el mismo.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.ac import AC\n",
    "\n",
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando correctamente un cuantificador\n",
    "\n",
    "Hasta ahora hemos hecho nuestras pruebas sobre una sola bag, con una prevalencia fija. Pero, no sería más adecuado crear varias bags con prior probability shift y calcular el error que cometemos? Esto se puede realizar fácilmente con un generador de bags incluido en **quantificationlib**. Veamos como se usa.\n",
    "\n",
    "📝 ***Hazlo tú mismo**: Utilizando `prev_true` e `indexes` devuelto, evalúa los cuantificadores CC y AC en cada una de las bags, calculando el error absoluto medio para las 50 bags. `prev_true` tendrá una forma (n_classes, n_bags) e `indexes` tendrá una forma (bag_size, n_bags).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "\n",
    "n_bags = 50\n",
    "bag_size = 500\n",
    "\n",
    "bag_generator = PriorShift_BagGenerator(n_bags=n_bags, bag_size=bag_size, min_prevalence=None)\n",
    "# prev_true es la prevalencia real de cada bag y indexes son los índices de los ejemplos de test que pertenecen a cada bag.\n",
    "# prev_true tiene forma (2, n_bags) y indexes tiene forma (bag_size, n_bags)\n",
    "prev_true, indexes = bag_generator.generate_bags(X_test, y_test)\n",
    "\n",
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizandolo gráficamente\n",
    "Otra manera de ver el rendimiento de los cuantificadores es visualizarlo gráficamente. Podemos pintar en un gráfico de dos dimesiones, donde el eje X representa la prevalencia real y el eje Y representa la prevalencia estimada. La linea x=y representaría el cuantificador perfecto (aquel que es capaz de predecir la prevalencia real de la bag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_true = prev_true[1, :]  # Prevalencia real de la clase positiva\n",
    "preds_cc = preds_cc[1, :]  # Predicciones del cuantificador CC\n",
    "preds_ac = preds_ac[1, :]  # Predicciones del cuantificador AC\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Cuantificador perfecto (y = x)')  # línea y=x\n",
    "plt.scatter(prev_true, preds_cc, color='green', label='CC', marker='o')\n",
    "plt.scatter(prev_true, preds_ac, color='red', label='AC', marker='s')\n",
    "\n",
    "# Etiquetas y leyenda\n",
    "plt.xlabel('Prevalencia real')\n",
    "plt.ylabel('Prevalencia estimada')\n",
    "plt.title('Comparación de predicciones de cuantificadores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Entrena dos cuantificadores más. El primero basado en distribution matching (DFy) y el segundo basado en el agoritmo EM (EM), compara los resultados con AC y CC. Pinta estos cuantificadores en una gráfica como la vista anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "from quantificationlib.multiclass.em import EM\n",
    "from quantificationlib.multiclass.df import DFy\n",
    "\n",
    "n_bags = 50\n",
    "bag_size = 500\n",
    "\n",
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Utiliza los 5000 ejemplos de entrenamiento para reentrenar tus cuatro cuantificadores. Usa estos cuantificadores para cuantificar las 1000 muestras presentes en el directorio T1.train_dev/T1/public/dev_samples. Visualizalo también gráficamente.\n",
    "La prevalencia real de cada bag está en el archivo dev_prevalences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 [Extra]. Hiperparámetros de los cuantificadores.\n",
    "Algunos cuantificadores, como por ejemplo DFy tienen hiper-parámetros, como por ejemplo el número de bins o la función de distancia utilizada para comparar las distribuciones. Prueba a cambiar estos hiperparámetros y volver a ejecutar, ¿encuentras alguna diferencia? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4 [Extra]. Usando un dataset multiclase.\n",
    "\n",
    "Prueba a entrenar los cuantificadores utilizando un dataset multiclase: https://zenodo.org/records/11661820/files/T2.train_dev.zip?download=1. Todos los cuantificadores que hemos utilizado anteriormente son capaces también de resolver problemas multiclase.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
