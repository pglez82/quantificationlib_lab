{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller de cuantificación: Estimación de prevalencias por clase\n",
    "Pontentes: Pablo Gonzalez (gonzalezgpablo@uniovi.es) y Olaya Pérez (perezolaya@uniovi.es)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pglez82/quantificationlib_lab/blob/master/lab/lab.ipynb)\n",
    "\n",
    "### Parte 1: Descarga del dataset necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://zenodo.org/records/11661820/files/T1.train_dev.zip?download=1\"\n",
    "zip_path = \"T1.train_dev.zip\"\n",
    "extracted_folder = \"T1.train_dev\"\n",
    "\n",
    "# Download with system wget (Jupyter syntax)\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget -O $zip_path \"$zip_url\"\n",
    "else:\n",
    "    print(\"ZIP file already exists.\")\n",
    "\n",
    "# Extract if not already extracted\n",
    "if not os.path.exists(extracted_folder):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder)\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Dataset already extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Instalación de las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install quantificationlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3. Leyendo el dataset.\n",
    "Este dataset contiene reviews de productos de amazon. Cada review puede ser positiva o negativa (campo `label`). El texto de cada review ha sido convertido a una representación numérica para su facilidad de uso. Diponemos de 5000 ejemplos de entrenamiento (5000 opiniones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('T1.train_dev/T1/public/training_data.txt')\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la prevalencia de las clases original en el dataset de etrenamiento.\n",
    "Como podemos ver, un alto porcentaje de las opiniones son positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count examples per label\n",
    "label_counts = dataset['label'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(label_counts.index.astype(str), label_counts.values)\n",
    "plt.xlabel('Etiqueta (0 negativa, 1 positiva)')\n",
    "plt.ylabel('Número de ejemplos')\n",
    "plt.title('Distribución')\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo a cuantificar. El método Clasificar y Contar\n",
    "Vamos a empezar con la solución trivial del problema de la cuantificación: entrenar un clasificador y contar las predicciones de cada ejemplo de la bag de test que queremos cuantificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "X = dataset.drop(columns=[\"label\"]).values\n",
    "y = dataset[\"label\"].values\n",
    "\n",
    "#Dividimos nuestro dataset en train y test, separando el 30% de los ejemplos para test y asegurando que la proporción original de etiquetas se mantiene en ambos conjuntos.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(y_train)} ejemplos (Proporción positivos: {np.mean(y_train):.2f}) | Test: {len(y_test)} ejemplos (Proporción positivos: {np.mean(y_test):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un clasificador y clasificamos lo ejemplos de test. Como podemos ver, el error absoluto de este cuantificador (AE) es bajo, predice bastante bien la prevalencia de la clse positiva en la bag de test. Este problema es en realidad trivial ya que en nuestro setup la prevalencia de las clases **no ha cambiado** entre train y test: $P_{train}(y)=P_{test}(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# Predeccimos los ejemplos de test y contamos la proporción de positivos en las predicciones.\n",
    "cc_prevalence = np.mean(y_pred)\n",
    "true_prevalence = np.mean(y_test)\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje postivos): {cc_prevalence:.4f}\")\n",
    "print(f\"Porcentaje positivos real: {true_prevalence:.4f}\")\n",
    "print(f\"Error absoluto cuantificador: {np.abs(cc_prevalence-true_prevalence):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué sucede si la distribución $P(y)$ cambia entre train y test $P_{train}(y) \\neq P_{test}(y)$?\n",
    "Para probarlo, generamos una nueva bolsa de test con 500 ejemplos, pero en este caso, la mayoría van a ser negativos (400 de 500).\n",
    "Como podemos comprobar ahora, si repetimos el procedimiento de antes y utilizamos CC para cuantificar, el error absoluto entre la predicción del cuantificador y la prevalencia real es mucho mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los índices de los ejemplos negativos y positivos en el conjunto de test\n",
    "neg_indices = np.where(y_test == 0)[0]\n",
    "pos_indices = np.where(y_test == 1)[0]\n",
    "\n",
    "# Elegimos el número de ejemplos negativos y positivos que queremos en nuestra bag\n",
    "n_neg, n_pos = 400, 100\n",
    "\n",
    "# Muestreamos aleatoriamente con reemplazmiento los índices de los ejemplos negativos y positivos\n",
    "sampled_neg = np.random.choice(neg_indices, size=n_neg, replace=True)\n",
    "sampled_pos = np.random.choice(pos_indices, size=n_pos, replace=True)\n",
    "\n",
    "# Combinamos y barajamos los índices de la bag\n",
    "bag_indices = np.concatenate([sampled_neg, sampled_pos])\n",
    "np.random.shuffle(bag_indices)\n",
    "\n",
    "# Creamos la bag con los ejemplos seleccionados\n",
    "X_bag = X_test[bag_indices]\n",
    "y_bag = y_test[bag_indices]\n",
    "\n",
    "# Imprimir información sobre la bag\n",
    "print(f\"Número de ejemplos en test: {len(y_bag)} | Proporción positivos: {np.mean(y_bag):.1f}\")\n",
    "\n",
    "# Aplicamos el método clasificar y contar (CC) a la bag\n",
    "y_pred = clf.predict(X_bag)\n",
    "cc_prevalence = np.mean(y_pred)\n",
    "true_prevalence = np.mean(y_bag)\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje positivos): {cc_prevalence:.4f}\")\n",
    "print(f\"Porcentaje positivos real: {true_prevalence:.2f}\")\n",
    "print(f\"Error absoluto cuantificador: {np.abs(cc_prevalence-true_prevalence):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizando la cuantificación (quantificationlib)\n",
    "\n",
    "Hasta ahora hemos cuantificado, con un cuantificador trivial (CC) a mano. Para cuantificar disponemos de software específico, como por ejemplo la librería de cuantificación **quantificationlib** (https://aicgijon.github.io/quantificationlib/).\n",
    "\n",
    "Veamos como utilizar CC usando quantificationlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.cc import CC\n",
    "from quantificationlib.metrics.multiclass import mean_absolute_error\n",
    "\n",
    "# Creamos un objeto CC que corresponde al método clasificar y contar (CC) e indicamos que queremos el mismo clasificador que hemos utilizado antes (clf).\n",
    "quantifier_cc = CC(estimator_test=clf)\n",
    "quantifier_cc.fit(X_train,y_train)\n",
    "# Predeccimos la misma bag con el cuantificador CC (deberíamos de obtener los mismos resultados que antes)\n",
    "p_pred=quantifier_cc.predict(X_bag)\n",
    "\n",
    "true_prevalence = np.array([0.8,0.2])\n",
    "\n",
    "print(f\"Clasificar y contar (porcentaje postivos): {p_pred[1]}\")\n",
    "print(f\"Prevalencia real: {true_prevalence[1]}\")\n",
    "# También disponemos de funciones para calcular errores de cuantificación como el error absoluto\n",
    "print(f\"Error absoluto cuantificador: {mean_absolute_error(p_pred,true_prevalence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando cuantificadores más avanzados\n",
    "En este caso vamos a utilizar un cuantificador especialmente diseñador para lidiar con situaciones de prior probability shift. Este método es un cuantificador básico conocido como Adjusted Count (AC).\n",
    "\n",
    "Como podemos ver este cuantificador mejora muchísimo el resultado de CC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.baselines.ac import AC\n",
    "\n",
    "quantifier_ac = AC(estimator_train=clf, estimator_test=clf)\n",
    "quantifier_ac.fit(X_train,y_train)\n",
    "p_pred=quantifier_ac.predict(X_bag)\n",
    "\n",
    "print(f\"Adjusted count (porcentaje postivos): {p_pred[1]}\")\n",
    "print(f\"Prevalencia real: {true_prevalence[1]}\")\n",
    "print(f\"Error absoluto cuantificador: {mean_absolute_error(p_pred,true_prevalence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando correctamente un cuantificador\n",
    "\n",
    "Hasta ahora hemos hecho nuestras pruebas sobre una sola bag, con una prevalencia fija. Pero, no sería más adecuado crear varias bags con prior probability shift y calcular el error que cometemos? Esto se puede realizar fácilmente con un generador de bags incluido en **quantificationlib**. Veamos como se usa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "\n",
    "n_bags = 10\n",
    "bag_size = 500\n",
    "\n",
    "bag_generator = PriorShift_BagGenerator(n_bags=n_bags, bag_size=bag_size, min_prevalence=None)\n",
    "prev_true, indexes = bag_generator.generate_bags(X_test, y_test)\n",
    "errores_cc = np.zeros((n_bags))\n",
    "errores_ac = np.zeros((n_bags))\n",
    "\n",
    "for n_bag in range(10):\n",
    "   prev_pred_cc = quantifier_cc.predict(X_test[indexes[:, n_bag], :])\n",
    "   prev_pred_ac = quantifier_ac.predict(X_test[indexes[:, n_bag], :])\n",
    "   errores_cc[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_cc)\n",
    "   errores_ac[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_ac)\n",
    "   print('Prevalencia real=%f, CC=%f (AE=%f), AC=%f (AE=%f)' % (prev_true[1,n_bag],prev_pred_cc[1], errores_cc[n_bag] ,prev_pred_ac[1], errores_ac[n_bag]))\n",
    "\n",
    "print(f\"Error medio CC {np.mean(errores_cc):.4f}\")\n",
    "print(f\"Error medio AC {np.mean(errores_ac):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Entrena dos cuantificadores más. El primero basado en distribution matching (DFy) y el segundo basado en el agoritmo EM (EM), compara los resultados con AC y CC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantificationlib.bag_generator import PriorShift_BagGenerator\n",
    "from quantificationlib.multiclass.em import EM\n",
    "from quantificationlib.multiclass.df import DFy\n",
    "\n",
    "n_bags = 10\n",
    "bag_size = 500\n",
    "\n",
    "quantifier_dfy = DFy(estimator_train=clf, estimator_test=clf)\n",
    "quantifier_em = EM(estimator_train=clf, estimator_test=clf)\n",
    "quantifier_dfy.fit(X_train,y_train)\n",
    "quantifier_em.fit(X_train,y_train)\n",
    "\n",
    "bag_generator = PriorShift_BagGenerator(n_bags=n_bags, bag_size=bag_size, min_prevalence=None)\n",
    "prev_true, indexes = bag_generator.generate_bags(X_test, y_test)\n",
    "errores_cc = np.zeros((n_bags))\n",
    "errores_ac = np.zeros((n_bags))\n",
    "errores_dfy = np.zeros((n_bags))\n",
    "errores_em = np.zeros((n_bags))\n",
    "\n",
    "for n_bag in range(10):\n",
    "   prev_pred_cc = quantifier_cc.predict(X_test[indexes[:, n_bag], :])\n",
    "   prev_pred_ac = quantifier_ac.predict(X_test[indexes[:, n_bag], :])\n",
    "   prev_pred_dfy = quantifier_dfy.predict(X_test[indexes[:, n_bag], :])\n",
    "   prev_pred_em = quantifier_em.predict(X_test[indexes[:, n_bag], :])\n",
    "   errores_cc[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_cc)\n",
    "   errores_ac[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_ac)\n",
    "   errores_dfy[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_dfy)\n",
    "   errores_em[n_bag] = mean_absolute_error(prev_true[:,n_bag],prev_pred_em)\n",
    "   print('Prevalencia real=%f, CC=%f (AE=%f), AC=%f (AE=%f), DFy=%f (AE=%f), EM=%f (AE=%f)' % (prev_true[1,n_bag],prev_pred_cc[1], errores_cc[n_bag] ,prev_pred_ac[1], errores_ac[n_bag], prev_pred_dfy[1], errores_dfy[n_bag], prev_pred_em[1], errores_em[n_bag]))\n",
    "\n",
    "print(f\"Error medio CC {np.mean(errores_cc):.4f}\")\n",
    "print(f\"Error medio AC {np.mean(errores_ac):.4f}\")\n",
    "print(f\"Error medio DFy {np.mean(errores_dfy):.4f}\")\n",
    "print(f\"Error medio EM {np.mean(errores_em):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Utiliza los 5000 ejemplos de entrenamiento para reentrenar tus cuatro cuantificadores. Usa estos cuantificadores para cuantificar las 1000 muestras presentes en el directorio T1.train_dev/T1/public/dev_samples.\n",
    "La prevalencia real de cada bag está en el archivo dev_prevalences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer las muestras del directorio T1.train_dev/T1/public/dev_samples\n",
    "import os\n",
    "import pandas as pd\n",
    "dev_samples_path = 'T1.train_dev/T1/public/dev_samples'\n",
    "# Leer la prevalencia real de cada bag desde el archivo dev_prevalences.txt\n",
    "prev_true = pd.read_csv('T1.train_dev/T1/public/dev_prevalences.txt',index_col=0)\n",
    "bag_files = prev_true.index\n",
    "prev_true = prev_true.to_numpy()\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "quantifier_cc.fit(X,y)\n",
    "quantifier_ac.fit(X,y)\n",
    "quantifier_dfy.fit(X,y)\n",
    "quantifier_em.fit(X,y)\n",
    "errores_cc = np.zeros((1000))\n",
    "errores_ac = np.zeros((1000))\n",
    "errores_dfy = np.zeros((1000))\n",
    "errores_em = np.zeros((1000))\n",
    "for n_bag in bag_files:\n",
    "    file_path = os.path.join(dev_samples_path, str(n_bag) + '.txt')\n",
    "    df = pd.read_csv(file_path)\n",
    "    prev_pred_cc = quantifier_cc.predict(df.to_numpy())\n",
    "    prev_pred_ac = quantifier_ac.predict(df.to_numpy())\n",
    "    prev_pred_dfy = quantifier_dfy.predict(df.to_numpy())\n",
    "    prev_pred_em = quantifier_em.predict(df.to_numpy())\n",
    "    errores_cc[n_bag] = mean_absolute_error(prev_true[n_bag,:],prev_pred_cc)\n",
    "    errores_ac[n_bag] = mean_absolute_error(prev_true[n_bag,:],prev_pred_ac)\n",
    "    errores_dfy[n_bag] = mean_absolute_error(prev_true[n_bag,:],prev_pred_dfy)\n",
    "    errores_em[n_bag] = mean_absolute_error(prev_true[n_bag,:],prev_pred_em)\n",
    "\n",
    "print(f\"Error medio CC {np.mean(errores_cc):.4f}\")\n",
    "print(f\"Error medio AC {np.mean(errores_ac):.4f}\")\n",
    "print(f\"Error medio DFy {np.mean(errores_dfy):.4f}\")\n",
    "print(f\"Error medio EM {np.mean(errores_em):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
